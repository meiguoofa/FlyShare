---
layout:     post
title:      数据分析4
subtitle:   第二章第一节：数据清洗及特征处理
date:       2020-08-21
author:     flyshare
header-img: img/post-bg-hacker.jpg
catalog: true
tags:
    - Data Analysis
---




# 第二章第一节：数据清洗及特征处理


**【回顾&引言】前面一章的内容大家可以感觉到我们主要是对基础知识做一个梳理，让大家了解数据分析的一些操作，主要做了数据的各个角度的观察。那么在这里，我们主要是做数据分析的流程性学习，主要是包括了数据清洗以及数据的特征处理，数据重构以及数据可视化。这些内容是为数据分析最后的建模和模型评价做一个铺垫。**



#### 开始之前，导入numpy、pandas包和数据

#加载所需的库

```python
import numpy as np
import pandas as pd

#加载数据train.csv
df = pd.read_csv('train.csv')
```


## 2 第二章：数据清洗及特征处理
**我们拿到的数据通常是不干净的，所谓的不干净，就是数据中有缺失值，有一些异常点等，需要经过一定的处理才能继续做后面的分析或建模，所以拿到数据的第一步是进行数据清洗，本章我们将学习缺失值、重复值、字符串和数据转换等操作，将数据清洗成可以分析或建模的亚子。**


### 2.1 缺失值观察与处理
**我们拿到的数据经常会有很多缺失值，比如我们可以看到Cabin列存在NaN，那其他列还有没有缺失值，这些缺失值要怎么处理呢**

#### 2.1.1 任务一：缺失值观察

(1) 请查看每个特征缺失值个数  
(2) 请查看Age， Cabin， Embarked列的数据
以上方式都有多种方式，所以大家多多益善

```python
#写入代码
df.info()
```

```python
#写入代码
df.isnull().sum()
```
```python
#写入代码
df.head(3)
df[['Age','Cabin','Embarked']].head(3)
```

#### 2.1.2 任务二：对缺失值进行处理

-处理缺失值一般有几种思路

-请尝试对Age列的数据的缺失值进行处理

-请尝试使用不同的方法直接对整张表的缺失值进行处理


#### 处理缺失值的一般思路：
#### 提醒：可使用的函数有--->dropna函数与fillna函数

```python
df[df['Age']==None] = 0

#写入代码
df[df['Age'].isnull()] = 0

df.head(20)

#写入代码

df[df['Age']==np.nan] = 0

#写入代码

df.head()

```

**【思考1】dropna和fillna有哪些参数，分别如何使用呢?**

```python
df.dropna()

df.dropna().head()

很明显,使用dropna()，某一行如果有某一列或者多列数据为空，那么一整行数据都不会显示

fillna()，则是对数据进行填充，fillna(arg)，其中的arg便是你需要填充的数值

```

**【思考2】检索空缺值用np.nan要比用None好，这是为什么？**

数值列读取数据后，空缺值的数据类型为float64所以用None一般索引不到，比较的时候最好用np.nan

【参考】https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html

【参考】https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html


### 2.2 重复值观察与处理

**由于这样那样的原因，数据中会不会存在重复值呢，如果存在要怎样处理呢**

#### 2.2.1 任务一：请查看数据中的重复值

```python
#写入代码
df[df.duplicated()].groupby('Sex').head()
```

#### 2.2.2 任务二：对重复值进行处理
(1)重复值有哪些处理方式呢？

(2)处理我们数据的重复值

方法多多益善


#重复值有哪些处理方式：

```python
df.drop_duplicates().head()
```


####  2.2.3 任务三：将前面清洗的数据保存为csv格式

```python
df.to_csv('test.clear2.csv')
```

### 2.3 特征观察与处理
我们对特征进行一下观察，可以把特征大概分为两大类：  
数值型特征：Survived ，Pclass， Age ，SibSp， Parch， Fare，其中Survived， Pclass为离散型数值特征，Age，SibSp， Parch， Fare为连续型数值特征  
文本型特征：Name， Sex， Cabin，Embarked， Ticket，其中Sex， Cabin， Embarked， Ticket为类别型文本特征，数值型特征一般可以直接用于模型的训练，但有时候为了模型的稳定性及鲁棒性会对连续变量进行离散化。文本型特征往往需要转换成数值型特征才能用于建模分析。

#### 2.3.1 任务一：对年龄进行分箱（离散化）处理
(1) 分箱操作是什么？

(2) 将连续变量Age平均分箱成5个年龄段，并分别用类别变量12345表示  

(3) 将连续变量Age划分为[0,5) [5,15) [15,30) [30,50) [50,80)五个年龄段，并分别用类别变量12345表示  

(4) 将连续变量Age按10% 30% 50 70% 90%五个年龄段，并用分类变量12345表示

(5) 将上面的获得的数据分别进行保存，保存为csv格式


**分箱操作是什么:**
df['AgeBand'] = pd.cut(df['Age'],5,labels=['1','2','3','4','5'])

```python
#写入代码
df.to_csv('test_save.csv')

#写入代码
df['AgeBand'] = pd.cut(df['Age'] ,[0,5,15,30,50,80] , labels=['1','2','3','4','5'] )
df.head(5)

df.to_csv('test_cut.csv')
```

【参考】https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html

【参考】https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html

#### 2.3.2 任务二：对文本变量进行转换

(1) 查看文本变量名及种类  
(2) 将文本变量Sex， Cabin ，Embarked用数值变量12345表示  
(3) 将文本变量Sex， Cabin， Embarked用one-hot编码表示

```python
#写入代码
df['Sex'].value_counts()

df['Sex_num'] = df['Sex'].map({'male': 1 , 'female':2})

from sklearn.preprocessing import LabelEncoder

for idx in ['Cabin','Ticket']:
  lbl = LabelEncoder()
  label_dict = dict(zip(df[idx].unique(),range(df[idx].nunique())))
  df[idx+ "_labelEncoder"] = df[idx].map(label_dict)
  df[idx+ "_labelEncoder"] = lbl.fit_transform(df[idx].astype(str))

df.head()

df.head()

#写入代码
df['Cabin'].value_counts()

#写入代码
df['Embarked'].value_counts()

for feat in ["Age", "Embarked"]:
#     x = pd.get_dummies(df["Age"] // 6)
#     x = pd.get_dummies(pd.cut(df['Age'],5))
    x = pd.get_dummies(df[feat], prefix=feat)
    #x.head()
    df = pd.concat([df, x], axis=1)
    #df[feat] = pd.get_dummies(df[feat], prefix=feat)
    
df.head()
```

#### 2.3.3 任务三：从纯文本Name特征里提取出Titles的特征(所谓的Titles就是Mr,Miss,Mrs等)

```python
#写入代码

df['Title'] = df.Name.str.extract('([A-Za-z]+)\.',expand=False)
df.head()

#保存最终你完成的已经清理好的数据
df.to_csv('test_fin.csv')
```